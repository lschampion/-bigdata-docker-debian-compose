{
  "paragraphs": [
    {
      "text": "%sh\n\n#Only load a file to HDFS if it\u0027s not already there - because of this you can run all paragraphs as many times as you like.\nhadoop fs -test -e /grades.csv\n\nif ! hadoop fs -test -e /grades.csv\nthen\n    echo \"*******************************************\"\n    echo \"grades.csv is not in HDFS yet! Uploading...\"\n    echo \"*******************************************\"d\n    hadoop fs -put /data/grades.csv /\nfi",
      "user": "anonymous",
      "dateUpdated": "2022-05-10 00:26:47.724",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "sh",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sh",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "SLF4J: Class path contains multiple SLF4J bindings.\nSLF4J: Found binding in [jar:file:/usr/program/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/usr/program/tez/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/usr/program/hive/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\nSLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\n2022-05-10 00:26:49,372 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\nSLF4J: Class path contains multiple SLF4J bindings.\nSLF4J: Found binding in [jar:file:/usr/program/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/usr/program/tez/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/usr/program/hive/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\nSLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\n2022-05-10 00:26:51,907 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n*******************************************\ngrades.csv is not in HDFS yet! Uploading...\n*******************************************d\nSLF4J: Class path contains multiple SLF4J bindings.\nSLF4J: Found binding in [jar:file:/usr/program/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/usr/program/tez/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/usr/program/hive/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\nSLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\n2022-05-10 00:26:54,429 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1646274983838_2137241335",
      "id": "paragraph_1646190869576_761249469",
      "dateCreated": "2022-03-03 02:36:23.838",
      "dateStarted": "2022-05-10 00:26:47.732",
      "dateFinished": "2022-05-10 00:26:55.603",
      "status": "FINISHED"
    },
    {
      "text": "%sh\n\nhadoop fs -ls /",
      "user": "anonymous",
      "dateUpdated": "2022-05-10 00:25:26.934",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "sh",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sh",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "SLF4J: Class path contains multiple SLF4J bindings.\nSLF4J: Found binding in [jar:file:/usr/program/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/usr/program/tez/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/usr/program/hive/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\nSLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\n2022-05-10 00:25:28,560 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\nFound 7 items\n-rw-r--r--   1 root supergroup        747 2022-05-10 00:25 /grades.csv\ndrwxr-xr-x   - root supergroup          0 2022-05-10 00:23 /hbase\ndrwxr-xr-x   - root supergroup          0 2022-05-10 00:21 /log\ndrwxr-xr-x   - root supergroup          0 2022-05-10 00:23 /spark-jars\ndrwxr-xr-x   - root supergroup          0 2022-05-10 00:23 /tez\ndrwxr-xr-x   - root supergroup          0 2022-05-10 00:23 /tmp\ndrwxrwx---   - root supergroup          0 2022-05-10 00:22 /user\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1646274983839_905369701",
      "id": "paragraph_1646190869577_987705583",
      "dateCreated": "2022-03-03 02:36:23.839",
      "dateStarted": "2022-05-10 00:25:26.947",
      "dateFinished": "2022-05-10 00:25:29.652",
      "status": "FINISHED"
    },
    {
      "text": "%jdbc\n\n-- Does not support more than one statement per paragraph, it seems. Same goes for semicolon at the end of statements - errors out if you include it.\nDROP TABLE IF EXISTS grades",
      "user": "anonymous",
      "dateUpdated": "2022-05-10 00:25:36.085",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "Query executed successfully. Affected rows : -1\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1646274983839_505401481",
      "id": "paragraph_1646190869577_409561374",
      "dateCreated": "2022-03-03 02:36:23.839",
      "dateStarted": "2022-05-10 00:25:36.093",
      "dateFinished": "2022-05-10 00:25:40.562",
      "status": "FINISHED"
    },
    {
      "text": "%jdbc\n\nCREATE TABLE grades(\n    `Last name` STRING,\n    `First name` STRING,\n    `SSN` STRING,\n    `Test1` DOUBLE,\n    `Test2` INT,\n    `Test3` DOUBLE,\n    `Test4` DOUBLE,\n    `Final` DOUBLE,\n    `Grade` STRING)\nCOMMENT \u0027https://people.sc.fsu.edu/~jburkardt/data/csv/csv.html\u0027\nROW FORMAT DELIMITED\nFIELDS TERMINATED BY \u0027,\u0027\nSTORED AS TEXTFILE\ntblproperties(\"skip.header.line.count\"\u003d\"1\")",
      "user": "anonymous",
      "dateUpdated": "2022-05-10 00:25:44.815",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "Query executed successfully. Affected rows : -1\nINFO  : Compiling command(queryId\u003droot_20220510002545_4f2381e5-531d-481c-849b-9ee9b2276b1d): \n\nCREATE TABLE grades(\n    `Last name` STRING,\n    `First name` STRING,\n    `SSN` STRING,\n    `Test1` DOUBLE,\n    `Test2` INT,\n    `Test3` DOUBLE,\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1646274983840_1199882173",
      "id": "paragraph_1646190869577_1137362447",
      "dateCreated": "2022-03-03 02:36:23.840",
      "dateStarted": "2022-05-10 00:25:44.824",
      "dateFinished": "2022-05-10 00:25:46.946",
      "status": "FINISHED"
    },
    {
      "text": "%jdbc\n\nLOAD DATA INPATH \u0027/grades.csv\u0027 INTO TABLE grades",
      "user": "anonymous",
      "dateUpdated": "2022-05-10 00:27:08.028",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "Query executed successfully. Affected rows : -1\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1646274983840_242464875",
      "id": "paragraph_1646190869577_1770491614",
      "dateCreated": "2022-03-03 02:36:23.840",
      "dateStarted": "2022-05-10 00:27:08.035",
      "dateFinished": "2022-05-10 00:27:08.706",
      "status": "FINISHED"
    },
    {
      "text": "%jdbc\n\nselect * from grades;\n-- set hive.execution.engine\u003dmr;\nSELECT grade,count(1) sl FROM grades group by grade;",
      "user": "anonymous",
      "dateUpdated": "2022-05-10 00:27:21.082",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "last name": "string",
                      "first name": "string",
                      "ssn": "string",
                      "test1": "string",
                      "test2": "string",
                      "test3": "string",
                      "test4": "string",
                      "final": "string",
                      "grade": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                }
              },
              "commonSetting": {}
            }
          },
          "1": {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "grade": "string",
                      "sl": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                }
              },
              "commonSetting": {}
            }
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TABLE",
            "data": "last name\tfirst name\tssn\ttest1\ttest2\ttest3\ttest4\tfinal\tgrade\nAlfalfa\tAloysius\t123-45-6789\t40.0\t90\t100.0\t83.0\t49.0\tD-\nAlfred\tUniversity\t123-12-1234\t41.0\t97\t96.0\t97.0\t48.0\tD+\nGerty\tGramma\t567-89-0123\t41.0\t80\t60.0\t40.0\t44.0\tC\nAndroid\tElectric\t087-65-4321\t42.0\t23\t36.0\t45.0\t47.0\tB-\nBumpkin\tFred\t456-78-9012\t43.0\t78\t88.0\t77.0\t45.0\tA-\nRubble\tBetty\t234-56-7890\t44.0\t90\t80.0\t90.0\t46.0\tC-\nNoshow\tCecil\t345-67-8901\t45.0\t11\t-1.0\t4.0\t43.0\tF\nBuff\tBif\t632-79-9939\t46.0\t20\t30.0\t40.0\t50.0\tB+\nAirpump\tAndrew\t223-45-6789\t49.0\t1\t90.0\t100.0\t83.0\tA\nBackus\tJim\t143-12-1234\t48.0\t1\t97.0\t96.0\t97.0\tA+\nCarnivore\tArt\t565-89-0123\t44.0\t1\t80.0\t60.0\t40.0\tD+\nDandy\tJim\t087-75-4321\t47.0\t1\t23.0\t36.0\t45.0\tC+\nElephant\tIma\t456-71-9012\t45.0\t1\t78.0\t88.0\t77.0\tB-\nFranklin\tBenny\t234-56-2890\t50.0\t1\t90.0\t80.0\t90.0\tB-\nGeorge\tBoy\t345-67-3901\t40.0\t1\t11.0\t-1.0\t4.0\tB\nHeffalump\tHarvey\t632-79-9439\t30.0\t1\t20.0\t30.0\t40.0\tC\nAlfalfa\tAloysius\t123-45-6789\t40.0\t90\t100.0\t83.0\t49.0\tD-\nAlfred\tUniversity\t123-12-1234\t41.0\t97\t96.0\t97.0\t48.0\tD+\nGerty\tGramma\t567-89-0123\t41.0\t80\t60.0\t40.0\t44.0\tC\nAndroid\tElectric\t087-65-4321\t42.0\t23\t36.0\t45.0\t47.0\tB-\nBumpkin\tFred\t456-78-9012\t43.0\t78\t88.0\t77.0\t45.0\tA-\nRubble\tBetty\t234-56-7890\t44.0\t90\t80.0\t90.0\t46.0\tC-\nNoshow\tCecil\t345-67-8901\t45.0\t11\t-1.0\t4.0\t43.0\tF\nBuff\tBif\t632-79-9939\t46.0\t20\t30.0\t40.0\t50.0\tB+\nAirpump\tAndrew\t223-45-6789\t49.0\t1\t90.0\t100.0\t83.0\tA\nBackus\tJim\t143-12-1234\t48.0\t1\t97.0\t96.0\t97.0\tA+\nCarnivore\tArt\t565-89-0123\t44.0\t1\t80.0\t60.0\t40.0\tD+\nDandy\tJim\t087-75-4321\t47.0\t1\t23.0\t36.0\t45.0\tC+\nElephant\tIma\t456-71-9012\t45.0\t1\t78.0\t88.0\t77.0\tB-\nFranklin\tBenny\t234-56-2890\t50.0\t1\t90.0\t80.0\t90.0\tB-\nGeorge\tBoy\t345-67-3901\t40.0\t1\t11.0\t-1.0\t4.0\tB\nHeffalump\tHarvey\t632-79-9439\t30.0\t1\t20.0\t30.0\t40.0\tC\n"
          },
          {
            "type": "TABLE",
            "data": "grade\tsl\nA\t2\nA+\t2\nA-\t2\nB\t2\nB+\t2\nB-\t6\nC\t4\nC+\t2\nC-\t2\nD+\t4\nD-\t2\nF\t2\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1646274983840_110646290",
      "id": "paragraph_1646190869577_1331104341",
      "dateCreated": "2022-03-03 02:36:23.840",
      "dateStarted": "2022-05-10 00:27:21.088",
      "dateFinished": "2022-05-10 00:27:43.448",
      "status": "FINISHED"
    },
    {
      "text": "%sh\n\n# Take a look at the warehouse directory, specifically where our Hive table is stored.\n hadoop fs -ls /usr/hive/warehouse/grades",
      "user": "anonymous",
      "dateUpdated": "2022-05-10 00:27:49.507",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "sh",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sh",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "SLF4J: Class path contains multiple SLF4J bindings.\nSLF4J: Found binding in [jar:file:/usr/program/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/usr/program/tez/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/usr/program/hive/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\nSLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\n2022-05-10 00:27:51,086 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\nFound 2 items\n-rw-r--r--   1 root supergroup        747 2022-05-10 00:25 /usr/hive/warehouse/grades/grades.csv\n-rw-r--r--   1 root supergroup        747 2022-05-10 00:26 /usr/hive/warehouse/grades/grades_copy_1.csv\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1646274983840_1857387149",
      "id": "paragraph_1646190869577_330115865",
      "dateCreated": "2022-03-03 02:36:23.840",
      "dateStarted": "2022-05-10 00:27:49.512",
      "dateFinished": "2022-05-10 00:27:52.107",
      "status": "FINISHED"
    },
    {
      "text": "%sh\n\n# Put the file back into HDFS - it was moved to warehouse directory when we loaded it with Hive.\nhadoop fs -put /data/grades.csv /\nhadoop fs -ls /",
      "user": "anonymous",
      "dateUpdated": "2022-05-10 00:28:04.994",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "sh",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sh",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "SLF4J: Class path contains multiple SLF4J bindings.\nSLF4J: Found binding in [jar:file:/usr/program/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/usr/program/tez/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/usr/program/hive/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\nSLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\n2022-05-10 00:28:06,576 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\nput: `/grades.csv\u0027: File exists\nSLF4J: Class path contains multiple SLF4J bindings.\nSLF4J: Found binding in [jar:file:/usr/program/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/usr/program/tez/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/usr/program/hive/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\nSLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\n2022-05-10 00:28:09,079 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\nFound 8 items\n-rw-r--r--   1 root supergroup        747 2022-05-10 00:27 /grades.csv\ndrwxr-xr-x   - root supergroup          0 2022-05-10 00:23 /hbase\ndrwxr-xr-x   - root supergroup          0 2022-05-10 00:21 /log\ndrwxr-xr-x   - root supergroup          0 2022-05-10 00:23 /spark-jars\ndrwxr-xr-x   - root supergroup          0 2022-05-10 00:23 /tez\ndrwxr-xr-x   - root supergroup          0 2022-05-10 00:27 /tmp\ndrwxrwx---   - root supergroup          0 2022-05-10 00:22 /user\ndrwxr-xr-x   - root supergroup          0 2022-05-10 00:25 /usr\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1646274983840_1790918675",
      "id": "paragraph_1646190869577_165553293",
      "dateCreated": "2022-03-03 02:36:23.840",
      "dateStarted": "2022-05-10 00:28:04.999",
      "dateFinished": "2022-05-10 00:28:10.115",
      "status": "FINISHED"
    },
    {
      "text": "%spark\n// use hivemetadata and read hdfs file directly\nspark.sql(\"select * from grades\").show()",
      "user": "anonymous",
      "dateUpdated": "2022-05-10 00:28:13.721",
      "progress": 100,
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+---------+----------+-----------+-----+-----+-----+-----+-----+-----+\n|last name|first name|        ssn|test1|test2|test3|test4|final|grade|\n+---------+----------+-----------+-----+-----+-----+-----+-----+-----+\n|Last name|First name|        SSN| null| null| null| null| null|Grade|\n|  Alfalfa|  Aloysius|123-45-6789| 40.0|   90|100.0| 83.0| 49.0|   D-|\n|   Alfred|University|123-12-1234| 41.0|   97| 96.0| 97.0| 48.0|   D+|\n|    Gerty|    Gramma|567-89-0123| 41.0|   80| 60.0| 40.0| 44.0|    C|\n|  Android|  Electric|087-65-4321| 42.0|   23| 36.0| 45.0| 47.0|   B-|\n|  Bumpkin|      Fred|456-78-9012| 43.0|   78| 88.0| 77.0| 45.0|   A-|\n|   Rubble|     Betty|234-56-7890| 44.0|   90| 80.0| 90.0| 46.0|   C-|\n|   Noshow|     Cecil|345-67-8901| 45.0|   11| -1.0|  4.0| 43.0|    F|\n|     Buff|       Bif|632-79-9939| 46.0|   20| 30.0| 40.0| 50.0|   B+|\n|  Airpump|    Andrew|223-45-6789| 49.0|    1| 90.0|100.0| 83.0|    A|\n|   Backus|       Jim|143-12-1234| 48.0|    1| 97.0| 96.0| 97.0|   A+|\n|Carnivore|       Art|565-89-0123| 44.0|    1| 80.0| 60.0| 40.0|   D+|\n|    Dandy|       Jim|087-75-4321| 47.0|    1| 23.0| 36.0| 45.0|   C+|\n| Elephant|       Ima|456-71-9012| 45.0|    1| 78.0| 88.0| 77.0|   B-|\n| Franklin|     Benny|234-56-2890| 50.0|    1| 90.0| 80.0| 90.0|   B-|\n|   George|       Boy|345-67-3901| 40.0|    1| 11.0| -1.0|  4.0|    B|\n|Heffalump|    Harvey|632-79-9439| 30.0|    1| 20.0| 30.0| 40.0|    C|\n|Last name|First name|        SSN| null| null| null| null| null|Grade|\n|  Alfalfa|  Aloysius|123-45-6789| 40.0|   90|100.0| 83.0| 49.0|   D-|\n|   Alfred|University|123-12-1234| 41.0|   97| 96.0| 97.0| 48.0|   D+|\n+---------+----------+-----------+-----+-----+-----+-----+-----+-----+\nonly showing top 20 rows\n\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://zeppelin:4040/jobs/job?id\u003d0"
            },
            {
              "jobUrl": "http://zeppelin:4040/jobs/job?id\u003d1"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1650120939787_268513790",
      "id": "paragraph_1650120939787_268513790",
      "dateCreated": "2022-04-16 14:55:39.787",
      "dateStarted": "2022-05-10 00:28:13.727",
      "dateFinished": "2022-05-10 00:29:15.468",
      "status": "FINISHED"
    },
    {
      "text": "%spark\n\n// Basic Spark functions\nspark.range(1000 * 1000 * 1000).count()",
      "user": "anonymous",
      "dateUpdated": "2022-05-10 00:29:22.726",
      "progress": 66,
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\u001b[1m\u001b[34mres2\u001b[0m: \u001b[1m\u001b[32mLong\u001b[0m \u003d 1000000000\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://zeppelin:4040/jobs/job?id\u003d2"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1646274983840_763975391",
      "id": "paragraph_1646190869577_411847481",
      "dateCreated": "2022-03-03 02:36:23.840",
      "dateStarted": "2022-05-10 00:29:22.731",
      "dateFinished": "2022-05-10 00:29:27.748",
      "status": "FINISHED"
    },
    {
      "text": "%spark\n// Dataframes\nval df \u003d Seq(\n  (\"One\", 1),\n  (\"Two\", 2),\n  (\"Three\", 3),\n  (\"Four\", 4)\n).toDF(\"This is\", \"an example\")\ndf.show()",
      "user": "anonymous",
      "dateUpdated": "2022-05-10 00:29:30.157",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+-------+----------+\n|This is|an example|\n+-------+----------+\n|    One|         1|\n|    Two|         2|\n|  Three|         3|\n|   Four|         4|\n+-------+----------+\n\n\u001b[1m\u001b[34mdf\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m \u003d [This is: string, an example: int]\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1646274983840_1998279222",
      "id": "paragraph_1646190869577_1442830525",
      "dateCreated": "2022-03-03 02:36:23.840",
      "dateStarted": "2022-05-10 00:29:30.163",
      "dateFinished": "2022-05-10 00:29:32.704",
      "status": "FINISHED"
    },
    {
      "text": "%spark\n\n// Read CSV file from HDFS into Dataframe\nval df \u003d spark.read.format(\"csv\").option(\"header\", \"true\").load(\"/grades.csv\")\ndf.show()",
      "user": "anonymous",
      "dateUpdated": "2022-05-10 00:29:35.110",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+---------+----------+-----------+-----+-----+-----+-----+-----+-----+\n|Last name|First name|        SSN|Test1|Test2|Test3|Test4|Final|Grade|\n+---------+----------+-----------+-----+-----+-----+-----+-----+-----+\n|  Alfalfa|  Aloysius|123-45-6789|   40|   90|  100|   83|   49|   D-|\n|   Alfred|University|123-12-1234|   41|   97|   96|   97|   48|   D+|\n|    Gerty|    Gramma|567-89-0123|   41|   80|   60|   40|   44|    C|\n|  Android|  Electric|087-65-4321|   42|   23|   36|   45|   47|   B-|\n|  Bumpkin|      Fred|456-78-9012|   43|   78|   88|   77|   45|   A-|\n|   Rubble|     Betty|234-56-7890|   44|   90|   80|   90|   46|   C-|\n|   Noshow|     Cecil|345-67-8901|   45|   11|   -1|    4|   43|    F|\n|     Buff|       Bif|632-79-9939|   46|   20|   30|   40|   50|   B+|\n|  Airpump|    Andrew|223-45-6789|   49|    1|   90|  100|   83|    A|\n|   Backus|       Jim|143-12-1234|   48|    1|   97|   96|   97|   A+|\n|Carnivore|       Art|565-89-0123|   44|    1|   80|   60|   40|   D+|\n|    Dandy|       Jim|087-75-4321|   47|    1|   23|   36|   45|   C+|\n| Elephant|       Ima|456-71-9012|   45|    1|   78|   88|   77|   B-|\n| Franklin|     Benny|234-56-2890|   50|    1|   90|   80|   90|   B-|\n|   George|       Boy|345-67-3901|   40|    1|   11|   -1|    4|    B|\n|Heffalump|    Harvey|632-79-9439|   30|    1|   20|   30|   40|    C|\n+---------+----------+-----------+-----+-----+-----+-----+-----+-----+\n\n\u001b[1m\u001b[34mdf\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m \u003d [Last name: string, First name: string ... 7 more fields]\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://zeppelin:4040/jobs/job?id\u003d3"
            },
            {
              "jobUrl": "http://zeppelin:4040/jobs/job?id\u003d4"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1646274983840_67053625",
      "id": "paragraph_1646190869577_966950759",
      "dateCreated": "2022-03-03 02:36:23.840",
      "dateStarted": "2022-05-10 00:29:35.115",
      "dateFinished": "2022-05-10 00:29:38.671",
      "status": "FINISHED"
    },
    {
      "text": "%spark\n\n// Spark SQL and temporary views\ndf.createOrReplaceTempView(\"df\")\nspark.sql(\"SHOW TABLES\").show()",
      "user": "anonymous",
      "dateUpdated": "2022-05-10 00:29:45.103",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+--------+---------+-----------+\n|database|tableName|isTemporary|\n+--------+---------+-----------+\n| default|   grades|      false|\n|        |       df|       true|\n+--------+---------+-----------+\n\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1646274983840_763361406",
      "id": "paragraph_1646190869577_370530194",
      "dateCreated": "2022-03-03 02:36:23.840",
      "dateStarted": "2022-05-10 00:29:45.107",
      "dateFinished": "2022-05-10 00:29:45.850",
      "status": "FINISHED"
    },
    {
      "text": "%spark\n\nspark.sql(\"SELECT * FROM df WHERE Final \u003e 50\").show()",
      "user": "anonymous",
      "dateUpdated": "2022-05-10 00:29:51.805",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+---------+----------+-----------+-----+-----+-----+-----+-----+-----+\n|Last name|First name|        SSN|Test1|Test2|Test3|Test4|Final|Grade|\n+---------+----------+-----------+-----+-----+-----+-----+-----+-----+\n|  Airpump|    Andrew|223-45-6789|   49|    1|   90|  100|   83|    A|\n|   Backus|       Jim|143-12-1234|   48|    1|   97|   96|   97|   A+|\n| Elephant|       Ima|456-71-9012|   45|    1|   78|   88|   77|   B-|\n| Franklin|     Benny|234-56-2890|   50|    1|   90|   80|   90|   B-|\n+---------+----------+-----------+-----+-----+-----+-----+-----+-----+\n\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://zeppelin:4040/jobs/job?id\u003d5"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1646274983841_229411474",
      "id": "paragraph_1646190869577_985233221",
      "dateCreated": "2022-03-03 02:36:23.841",
      "dateStarted": "2022-05-10 00:29:51.809",
      "dateFinished": "2022-05-10 00:29:52.853",
      "status": "FINISHED"
    },
    {
      "text": "%spark.pyspark\n\n# Check Python version - 2 not allowed.\nimport sys\nprint(sys.version)",
      "user": "anonymous",
      "dateUpdated": "2022-05-10 00:30:05.229",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "3.7.5 (default, May  8 2022, 20:52:19) \n[GCC 8.5.0 20210514 (Red Hat 8.5.0-4)]\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1646274983841_1773721208",
      "id": "paragraph_1646190869577_1175475651",
      "dateCreated": "2022-03-03 02:36:23.841",
      "dateStarted": "2022-05-10 00:30:05.234",
      "dateFinished": "2022-05-10 00:30:05.262",
      "status": "FINISHED"
    },
    {
      "text": "%spark.pyspark\n\n#  Basic Spark functions\nspark.range(1000 * 1000 * 1000).count()",
      "user": "anonymous",
      "dateUpdated": "2022-05-10 00:30:19.768",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "1000000000\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://zeppelin:4040/jobs/job?id\u003d7"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1646274983841_1962376825",
      "id": "paragraph_1646190869577_1865821110",
      "dateCreated": "2022-03-03 02:36:23.841",
      "dateStarted": "2022-05-10 00:30:19.773",
      "dateFinished": "2022-05-10 00:30:20.095",
      "status": "FINISHED"
    },
    {
      "text": "%spark.pyspark\n\n# Dataframes\ndf \u003d sqlContext.createDataFrame([(\"One\", 1), (\"Two\", 2), (\"Three\", 3), (\"Four\", 4)], (\"This is\", \"an example\"))\ndf.show()",
      "user": "anonymous",
      "dateUpdated": "2022-05-10 00:30:24.326",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+-------+----------+\n|This is|an example|\n+-------+----------+\n|    One|         1|\n|    Two|         2|\n|  Three|         3|\n|   Four|         4|\n+-------+----------+\n\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://zeppelin:4040/jobs/job?id\u003d8"
            },
            {
              "jobUrl": "http://zeppelin:4040/jobs/job?id\u003d9"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1646274983841_1397182873",
      "id": "paragraph_1646190869578_218897458",
      "dateCreated": "2022-03-03 02:36:23.841",
      "dateStarted": "2022-05-10 00:30:24.330",
      "dateFinished": "2022-05-10 00:30:25.561",
      "status": "FINISHED"
    },
    {
      "text": "%spark.pyspark\n\n# Read CSV file from HDFS into Dataframe\ndf \u003d spark.read.format(\"csv\").option(\"header\", \"true\").load(\"/grades.csv\")\ndf.show()",
      "user": "anonymous",
      "dateUpdated": "2022-05-10 00:30:28.221",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+---------+----------+-----------+-----+-----+-----+-----+-----+-----+\n|Last name|First name|        SSN|Test1|Test2|Test3|Test4|Final|Grade|\n+---------+----------+-----------+-----+-----+-----+-----+-----+-----+\n|  Alfalfa|  Aloysius|123-45-6789|   40|   90|  100|   83|   49|   D-|\n|   Alfred|University|123-12-1234|   41|   97|   96|   97|   48|   D+|\n|    Gerty|    Gramma|567-89-0123|   41|   80|   60|   40|   44|    C|\n|  Android|  Electric|087-65-4321|   42|   23|   36|   45|   47|   B-|\n|  Bumpkin|      Fred|456-78-9012|   43|   78|   88|   77|   45|   A-|\n|   Rubble|     Betty|234-56-7890|   44|   90|   80|   90|   46|   C-|\n|   Noshow|     Cecil|345-67-8901|   45|   11|   -1|    4|   43|    F|\n|     Buff|       Bif|632-79-9939|   46|   20|   30|   40|   50|   B+|\n|  Airpump|    Andrew|223-45-6789|   49|    1|   90|  100|   83|    A|\n|   Backus|       Jim|143-12-1234|   48|    1|   97|   96|   97|   A+|\n|Carnivore|       Art|565-89-0123|   44|    1|   80|   60|   40|   D+|\n|    Dandy|       Jim|087-75-4321|   47|    1|   23|   36|   45|   C+|\n| Elephant|       Ima|456-71-9012|   45|    1|   78|   88|   77|   B-|\n| Franklin|     Benny|234-56-2890|   50|    1|   90|   80|   90|   B-|\n|   George|       Boy|345-67-3901|   40|    1|   11|   -1|    4|    B|\n|Heffalump|    Harvey|632-79-9439|   30|    1|   20|   30|   40|    C|\n+---------+----------+-----------+-----+-----+-----+-----+-----+-----+\n\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {
        "jobUrl": {
          "propertyName": "jobUrl",
          "label": "SPARK JOB",
          "tooltip": "View in Spark web UI",
          "group": "spark",
          "values": [
            {
              "jobUrl": "http://zeppelin:4040/jobs/job?id\u003d10"
            },
            {
              "jobUrl": "http://zeppelin:4040/jobs/job?id\u003d11"
            }
          ],
          "interpreterSettingId": "spark"
        }
      },
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1646274983841_274174689",
      "id": "paragraph_1646190869578_1642739134",
      "dateCreated": "2022-03-03 02:36:23.841",
      "dateStarted": "2022-05-10 00:30:28.224",
      "dateFinished": "2022-05-10 00:30:29.079",
      "status": "FINISHED"
    },
    {
      "text": "%livy\n\n// Scala Spark over Livy\nspark.range(1000 * 1000 * 999).count()",
      "user": "anonymous",
      "dateUpdated": "2022-05-10 00:30:32.295",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "ERROR",
        "msg": [
          {
            "type": "TEXT",
            "data": "org.apache.zeppelin.interpreter.InterpreterException: org.apache.zeppelin.interpreter.InterpreterException: org.apache.zeppelin.interpreter.InterpreterException: Fail to create session, please check livy interpreter log and livy server log\n\tat org.apache.zeppelin.interpreter.LazyOpenInterpreter.open(LazyOpenInterpreter.java:76)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:844)\n\tat org.apache.zeppelin.interpreter.remote.RemoteInterpreterServer$InterpretJob.jobRun(RemoteInterpreterServer.java:752)\n\tat org.apache.zeppelin.scheduler.Job.run(Job.java:172)\n\tat org.apache.zeppelin.scheduler.AbstractScheduler.runJob(AbstractScheduler.java:132)\n\tat org.apache.zeppelin.scheduler.FIFOScheduler.lambda$runJobInScheduler$0(FIFOScheduler.java:42)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.zeppelin.interpreter.InterpreterException: org.apache.zeppelin.interpreter.InterpreterException: Fail to create session, please check livy interpreter log and livy server log\n\tat org.apache.zeppelin.interpreter.LazyOpenInterpreter.open(LazyOpenInterpreter.java:76)\n\tat org.apache.zeppelin.interpreter.Interpreter.getInterpreterInTheSameSessionByClassName(Interpreter.java:322)\n\tat org.apache.zeppelin.interpreter.Interpreter.getInterpreterInTheSameSessionByClassName(Interpreter.java:333)\n\tat org.apache.zeppelin.livy.BaseLivyInterpreter.open(BaseLivyInterpreter.java:160)\n\tat org.apache.zeppelin.interpreter.LazyOpenInterpreter.open(LazyOpenInterpreter.java:70)\n\t... 8 more\nCaused by: org.apache.zeppelin.interpreter.InterpreterException: Fail to create session, please check livy interpreter log and livy server log\n\tat org.apache.zeppelin.livy.LivySharedInterpreter.open(LivySharedInterpreter.java:68)\n\tat org.apache.zeppelin.interpreter.LazyOpenInterpreter.open(LazyOpenInterpreter.java:70)\n\t... 12 more\nCaused by: org.apache.zeppelin.livy.LivyException: org.apache.zeppelin.livy.LivyException: The creation of session 0 is timeout within 120 seconds, appId: application_1652142098641_0004, log:\nstdout: \n1729 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jackson-annotations-2.10.0.jar\n1731 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jackson-core-2.10.0.jar\n1733 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jackson-core-asl-1.9.13.jar\n1736 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jackson-databind-2.10.0.jar\n1738 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jackson-dataformat-yaml-2.10.0.jar\n1740 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jackson-datatype-jsr310-2.10.3.jar\n1742 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jackson-jaxrs-base-2.9.5.jar\n1745 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jackson-jaxrs-json-provider-2.9.5.jar\n1747 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jackson-mapper-asl-1.9.13.jar\n1751 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jackson-module-jaxb-annotations-2.10.0.jar\n1753 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jackson-module-paranamer-2.10.0.jar\n1756 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jackson-module-scala_2.12-2.10.0.jar\n1759 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jakarta.activation-api-1.2.1.jar\n1762 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jakarta.annotation-api-1.3.5.jar\n1765 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jakarta.inject-2.6.1.jar\n1767 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jakarta.validation-api-2.0.2.jar\n1771 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jakarta.ws.rs-api-2.1.6.jar\n1776 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jakarta.xml.bind-api-2.3.2.jar\n1780 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/janino-3.0.16.jar\n1783 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/javassist-3.25.0-GA.jar\n1785 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/javax.inject-1.jar\n1787 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/javax.jdo-3.2.0-m3.jar\n1789 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/javax.servlet-api-3.1.0.jar\n1798 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/javolution-5.5.1.jar\n1800 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jaxb-api-2.2.11.jar\n1803 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jaxb-runtime-2.3.2.jar\n1806 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jcip-annotations-1.0-1.jar\n1808 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jcl-over-slf4j-1.7.30.jar\n1811 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jdo-api-3.0.1.jar\n1813 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jersey-client-2.30.jar\n1816 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jersey-common-2.30.jar\n1818 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jersey-container-servlet-2.30.jar\n1820 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jersey-container-servlet-core-2.30.jar\n1822 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jersey-hk2-2.30.jar\n1824 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jersey-media-jaxb-2.30.jar\n1826 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jersey-server-2.30.jar\n1829 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jline-2.14.6.jar\n1832 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/joda-time-2.10.5.jar\n1833 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jodd-core-3.5.2.jar\n1835 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jpam-1.1.jar\n1839 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/json-1.8.jar\n1841 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/json-smart-2.3.jar\n1843 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/json4s-ast_2.12-3.6.6.jar\n1845 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/json4s-core_2.12-3.6.6.jar\n1847 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/json4s-jackson_2.12-3.6.6.jar\n1849 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/json4s-scalap_2.12-3.6.6.jar\n1851 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jsp-api-2.1.jar\n1854 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jsr305-3.0.0.jar\n1856 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jta-1.1.jar\n1859 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jul-to-slf4j-1.7.30.jar\n1861 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/kerb-admin-1.0.1.jar\n1863 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/kerb-client-1.0.1.jar\n1866 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/kerb-common-1.0.1.jar\n1868 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/kerb-core-1.0.1.jar\n1870 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/kerb-crypto-1.0.1.jar\n1873 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/kerb-identity-1.0.1.jar\n1875 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/kerb-server-1.0.1.jar\n1877 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/kerb-simplekdc-1.0.1.jar\n1879 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/kerb-util-1.0.1.jar\n1881 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/kerby-asn1-1.0.1.jar\n1883 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/kerby-config-1.0.1.jar\n1885 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/kerby-pkix-1.0.1.jar\n1887 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/kerby-util-1.0.1.jar\n1890 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/kerby-xdr-1.0.1.jar\n1892 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/kryo-shaded-4.0.2.jar\n1894 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/kubernetes-client-4.9.2.jar\n1896 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/kubernetes-model-4.9.2.jar\n1898 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/kubernetes-model-common-4.9.2.jar\n1901 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/leveldbjni-all-1.8.jar\n1903 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/libfb303-0.9.3.jar\n1905 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/libthrift-0.12.0.jar\n1907 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/log4j-1.2.17.jar\n1909 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/logging-interceptor-3.12.6.jar\n1911 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/lz4-java-1.7.1.jar\n1913 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/machinist_2.12-0.6.8.jar\n1914 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/macro-compat_2.12-1.1.1.jar\n1917 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/mesos-1.4.0-shaded-protobuf.jar\n1920 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/metrics-core-4.1.1.jar\n1922 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/metrics-graphite-4.1.1.jar\n1924 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/metrics-jmx-4.1.1.jar\n1926 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/metrics-json-4.1.1.jar\n1928 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/metrics-jvm-4.1.1.jar\n1931 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/minlog-1.3.0.jar\n1933 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/mysql-connector-java-5.1.47.jar\n1934 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/netty-all-4.1.47.Final.jar\n1936 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/nimbus-jose-jwt-4.41.1.jar\n1939 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/objenesis-2.5.1.jar\n1941 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/okhttp-2.7.5.jar\n1943 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/okhttp-3.12.6.jar\n1946 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/okio-1.15.0.jar\n1948 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/opencsv-2.3.jar\n1950 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/orc-core-1.5.10.jar\n1952 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/orc-mapreduce-1.5.10.jar\n1954 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/orc-shims-1.5.10.jar\n1955 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/oro-2.0.8.jar\n1957 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/osgi-resource-locator-1.0.3.jar\n1959 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/paranamer-2.8.jar\n1961 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/parquet-column-1.10.1.jar\n1963 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/parquet-common-1.10.1.jar\n1967 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/parquet-encoding-1.10.1.jar\n1969 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/parquet-format-2.4.0.jar\n1971 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/parquet-hadoop-1.10.1.jar\n1975 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/parquet-jackson-1.10.1.jar\n1977 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/postgresql-42.2.8.jar\n1979 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/protobuf-java-2.5.0.jar\n1982 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/py4j-0.10.9.jar\n1984 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/pyrolite-4.30.jar\n1986 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/re2j-1.1.jar\n1989 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/scala-collection-compat_2.12-2.1.1.jar\n1990 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/scala-compiler-2.12.10.jar\n1992 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/scala-library-2.12.10.jar\n1994 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/scala-parser-combinators_2.12-1.1.2.jar\n1996 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/scala-reflect-2.12.10.jar\n1998 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/scala-xml_2.12-1.2.0.jar\n2001 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/shapeless_2.12-2.3.3.jar\n2002 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/shims-0.7.45.jar\n2004 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/slf4j-api-1.7.30.jar\n2006 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/slf4j-log4j12-1.7.30.jar\n2008 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/snakeyaml-1.24.jar\n2010 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/snappy-java-1.1.7.5.jar\n2013 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/spark-avro_2.12-3.0.0.jar\n2015 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/spark-catalyst_2.12-3.0.0.jar\n2016 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/spark-core_2.12-3.0.0.jar\n2018 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/spark-graphx_2.12-3.0.0.jar\n2020 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/spark-hive-thriftserver_2.12-3.0.0.jar\n2022 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/spark-hive_2.12-3.0.0.jar\n2024 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/spark-kubernetes_2.12-3.0.0.jar\n2027 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/spark-kvstore_2.12-3.0.0.jar\n2029 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/spark-launcher_2.12-3.0.0.jar\n2031 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/spark-mesos_2.12-3.0.0.jar\n2033 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/spark-mllib-local_2.12-3.0.0.jar\n2035 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/spark-mllib_2.12-3.0.0.jar\n2037 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/spark-network-common_2.12-3.0.0.jar\n2040 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/spark-network-shuffle_2.12-3.0.0.jar\n2042 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/spark-repl_2.12-3.0.0.jar\n2043 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/spark-sketch_2.12-3.0.0.jar\n2046 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/spark-sql_2.12-3.0.0.jar\n2048 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/spark-streaming_2.12-3.0.0.jar\n2050 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/spark-tags_2.12-3.0.0-tests.jar\n2052 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/spark-tags_2.12-3.0.0.jar\n2054 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/spark-unsafe_2.12-3.0.0.jar\n2058 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/spark-yarn_2.12-3.0.0.jar\n2060 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/spire-macros_2.12-0.17.0-M1.jar\n2063 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/spire-platform_2.12-0.17.0-M1.jar\n2066 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/spire-util_2.12-0.17.0-M1.jar\n2069 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/spire_2.12-0.17.0-M1.jar\n2071 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/stax-api-1.0.1.jar\n2074 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/stax2-api-3.1.4.jar\n2076 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/stream-2.9.6.jar\n2078 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/super-csv-2.2.0.jar\n2081 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/threeten-extra-1.5.0.jar\n2083 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/token-provider-1.0.1.jar\n2085 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/transaction-api-1.1.jar\n2087 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/univocity-parsers-2.8.3.jar\n2090 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/velocity-1.5.jar\n2092 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/woodstox-core-5.0.3.jar\n2094 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/xbean-asm7-shaded-4.15.jar\n2096 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/xz-1.5.jar\n2098 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/zjsonpatch-0.3.0.jar\n2100 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/zookeeper-3.4.14.jar\n2102 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/zstd-jni-1.4.4-3.jar\n2113 [main] INFO  org.apache.spark.deploy.yarn.Client  - Uploading resource file:/usr/program/livy/rsc-jars/asm-5.0.4.jar -\u003e hdfs://master:9000/user/root/.sparkStaging/application_1652142098641_0004/asm-5.0.4.jar\n2261 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation  - No unit for dfs.client.datanode-restart.timeout(30) assuming SECONDS\n2268 [main] INFO  org.apache.spark.deploy.yarn.Client  - Uploading resource file:/usr/program/livy/rsc-jars/livy-api-0.8.0-incubating-SNAPSHOT.jar -\u003e hdfs://master:9000/user/root/.sparkStaging/application_1652142098641_0004/livy-api-0.8.0-incubating-SNAPSHOT.jar\n2292 [main] INFO  org.apache.spark.deploy.yarn.Client  - Uploading resource file:/usr/program/livy/rsc-jars/livy-rsc-0.8.0-incubating-SNAPSHOT.jar -\u003e hdfs://master:9000/user/root/.sparkStaging/application_1652142098641_0004/livy-rsc-0.8.0-incubating-SNAPSHOT.jar\n2327 [main] INFO  org.apache.spark.deploy.yarn.Client  - Uploading resource file:/usr/program/livy/rsc-jars/livy-thriftserver-session-0.8.0-incubating-SNAPSHOT.jar -\u003e hdfs://master:9000/user/root/.sparkStaging/application_1652142098641_0004/livy-thriftserver-session-0.8.0-incubating-SNAPSHOT.jar\n2362 [main] WARN  org.apache.spark.deploy.yarn.Client  - Same name resource file:///usr/program/livy/rsc-jars/minlog-1.3.0.jar added multiple times to distributed cache\n2362 [main] WARN  org.apache.spark.deploy.yarn.Client  - Same name resource file:///usr/program/livy/rsc-jars/netty-all-4.1.47.Final.jar added multiple times to distributed cache\n2362 [main] WARN  org.apache.spark.deploy.yarn.Client  - Same name resource file:///usr/program/livy/rsc-jars/objenesis-2.5.1.jar added multiple times to distributed cache\n2363 [main] INFO  org.apache.spark.deploy.yarn.Client  - Uploading resource file:/usr/program/livy/rsc-jars/reflectasm-1.11.3.jar -\u003e hdfs://master:9000/user/root/.sparkStaging/application_1652142098641_0004/reflectasm-1.11.3.jar\n2394 [main] INFO  org.apache.spark.deploy.yarn.Client  - Uploading resource file:/usr/program/livy/repl_2.12-jars/commons-codec-1.9.jar -\u003e hdfs://master:9000/user/root/.sparkStaging/application_1652142098641_0004/commons-codec-1.9.jar\n2426 [main] INFO  org.apache.spark.deploy.yarn.Client  - Uploading resource file:/usr/program/livy/repl_2.12-jars/livy-core_2.12-0.8.0-incubating-SNAPSHOT.jar -\u003e hdfs://master:9000/user/root/.sparkStaging/application_1652142098641_0004/livy-core_2.12-0.8.0-incubating-SNAPSHOT.jar\n2460 [main] INFO  org.apache.spark.deploy.yarn.Client  - Uploading resource file:/usr/program/livy/repl_2.12-jars/livy-repl_2.12-0.8.0-incubating-SNAPSHOT.jar -\u003e hdfs://master:9000/user/root/.sparkStaging/application_1652142098641_0004/livy-repl_2.12-0.8.0-incubating-SNAPSHOT.jar\n2508 [main] INFO  org.apache.spark.deploy.yarn.Client  - Uploading resource file:/usr/program/spark/R/lib/sparkr.zip#sparkr -\u003e hdfs://master:9000/user/root/.sparkStaging/application_1652142098641_0004/sparkr.zip\n2562 [main] INFO  org.apache.spark.deploy.yarn.Client  - Uploading resource file:/usr/program/spark/python/lib/pyspark.zip -\u003e hdfs://master:9000/user/root/.sparkStaging/application_1652142098641_0004/pyspark.zip\n2591 [main] INFO  org.apache.spark.deploy.yarn.Client  - Uploading resource file:/usr/program/spark/python/lib/py4j-0.10.9-src.zip -\u003e hdfs://master:9000/user/root/.sparkStaging/application_1652142098641_0004/py4j-0.10.9-src.zip\n2614 [main] WARN  org.apache.spark.deploy.yarn.Client  - Same name resource file:///usr/program/spark/python/lib/pyspark.zip added multiple times to distributed cache\n2614 [main] WARN  org.apache.spark.deploy.yarn.Client  - Same name resource file:///usr/program/spark/python/lib/py4j-0.10.9-src.zip added multiple times to distributed cache\n2871 [main] INFO  org.apache.spark.deploy.yarn.Client  - Uploading resource file:/tmp/spark-13f8041e-33fa-4b96-ac58-21c3c5633827/__spark_conf__5810885990873377274.zip -\u003e hdfs://master:9000/user/root/.sparkStaging/application_1652142098641_0004/__spark_conf__.zip\n2945 [main] INFO  org.apache.spark.SecurityManager  - Changing view acls to: root\n2946 [main] INFO  org.apache.spark.SecurityManager  - Changing modify acls to: root\n2947 [main] INFO  org.apache.spark.SecurityManager  - Changing view acls groups to: \n2948 [main] INFO  org.apache.spark.SecurityManager  - Changing modify acls groups to: \n2948 [main] INFO  org.apache.spark.SecurityManager  - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\n3068 [main] INFO  org.apache.spark.deploy.yarn.Client  - Submitting application application_1652142098641_0004 to ResourceManager\n3137 [main] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl  - Submitted application application_1652142098641_0004\n3140 [main] INFO  org.apache.spark.deploy.yarn.Client  - Application report for application_1652142098641_0004 (state: ACCEPTED)\n3145 [main] INFO  org.apache.spark.deploy.yarn.Client  - \n\t client token: N/A\n\t diagnostics: N/A\n\t ApplicationMaster host: N/A\n\t ApplicationMaster RPC port: -1\n\t queue: root.root\n\t start time: 1652142641647\n\t final status: UNDEFINED\n\t tracking URL: http://master:8088/proxy/application_1652142098641_0004/\n\t user: root\n3150 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager  - Shutdown hook called\n3152 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager  - Deleting directory /tmp/spark-13f8041e-33fa-4b96-ac58-21c3c5633827\n3158 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager  - Deleting directory /tmp/spark-cb422152-c0a9-4261-8c0d-891796db1733\n\nstderr: \nSLF4J: Class path contains multiple SLF4J bindings.\nSLF4J: Found binding in [jar:file:/usr/program/spark/jars/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/usr/program/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\nSLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\n\nYARN Diagnostics: \nApplication application_1652142098641_0004 was killed by user root at 172.28.1.1\n\tat org.apache.zeppelin.livy.BaseLivyInterpreter.createSession(BaseLivyInterpreter.java:338)\n\tat org.apache.zeppelin.livy.BaseLivyInterpreter.initLivySession(BaseLivyInterpreter.java:186)\n\tat org.apache.zeppelin.livy.LivySharedInterpreter.open(LivySharedInterpreter.java:60)\n\t... 13 more\nCaused by: org.apache.zeppelin.livy.LivyException: The creation of session 0 is timeout within 120 seconds, appId: application_1652142098641_0004, log:\nstdout: \n1729 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jackson-annotations-2.10.0.jar\n1731 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jackson-core-2.10.0.jar\n1733 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jackson-core-asl-1.9.13.jar\n1736 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jackson-databind-2.10.0.jar\n1738 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jackson-dataformat-yaml-2.10.0.jar\n1740 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jackson-datatype-jsr310-2.10.3.jar\n1742 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jackson-jaxrs-base-2.9.5.jar\n1745 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jackson-jaxrs-json-provider-2.9.5.jar\n1747 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jackson-mapper-asl-1.9.13.jar\n1751 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jackson-module-jaxb-annotations-2.10.0.jar\n1753 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jackson-module-paranamer-2.10.0.jar\n1756 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jackson-module-scala_2.12-2.10.0.jar\n1759 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jakarta.activation-api-1.2.1.jar\n1762 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jakarta.annotation-api-1.3.5.jar\n1765 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jakarta.inject-2.6.1.jar\n1767 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jakarta.validation-api-2.0.2.jar\n1771 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jakarta.ws.rs-api-2.1.6.jar\n1776 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jakarta.xml.bind-api-2.3.2.jar\n1780 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/janino-3.0.16.jar\n1783 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/javassist-3.25.0-GA.jar\n1785 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/javax.inject-1.jar\n1787 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/javax.jdo-3.2.0-m3.jar\n1789 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/javax.servlet-api-3.1.0.jar\n1798 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/javolution-5.5.1.jar\n1800 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jaxb-api-2.2.11.jar\n1803 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jaxb-runtime-2.3.2.jar\n1806 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jcip-annotations-1.0-1.jar\n1808 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jcl-over-slf4j-1.7.30.jar\n1811 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jdo-api-3.0.1.jar\n1813 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jersey-client-2.30.jar\n1816 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jersey-common-2.30.jar\n1818 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jersey-container-servlet-2.30.jar\n1820 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jersey-container-servlet-core-2.30.jar\n1822 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jersey-hk2-2.30.jar\n1824 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jersey-media-jaxb-2.30.jar\n1826 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jersey-server-2.30.jar\n1829 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jline-2.14.6.jar\n1832 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/joda-time-2.10.5.jar\n1833 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jodd-core-3.5.2.jar\n1835 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jpam-1.1.jar\n1839 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/json-1.8.jar\n1841 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/json-smart-2.3.jar\n1843 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/json4s-ast_2.12-3.6.6.jar\n1845 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/json4s-core_2.12-3.6.6.jar\n1847 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/json4s-jackson_2.12-3.6.6.jar\n1849 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/json4s-scalap_2.12-3.6.6.jar\n1851 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jsp-api-2.1.jar\n1854 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jsr305-3.0.0.jar\n1856 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jta-1.1.jar\n1859 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/jul-to-slf4j-1.7.30.jar\n1861 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/kerb-admin-1.0.1.jar\n1863 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/kerb-client-1.0.1.jar\n1866 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/kerb-common-1.0.1.jar\n1868 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/kerb-core-1.0.1.jar\n1870 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/kerb-crypto-1.0.1.jar\n1873 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/kerb-identity-1.0.1.jar\n1875 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/kerb-server-1.0.1.jar\n1877 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/kerb-simplekdc-1.0.1.jar\n1879 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/kerb-util-1.0.1.jar\n1881 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/kerby-asn1-1.0.1.jar\n1883 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/kerby-config-1.0.1.jar\n1885 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/kerby-pkix-1.0.1.jar\n1887 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/kerby-util-1.0.1.jar\n1890 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/kerby-xdr-1.0.1.jar\n1892 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/kryo-shaded-4.0.2.jar\n1894 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/kubernetes-client-4.9.2.jar\n1896 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/kubernetes-model-4.9.2.jar\n1898 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/kubernetes-model-common-4.9.2.jar\n1901 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/leveldbjni-all-1.8.jar\n1903 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/libfb303-0.9.3.jar\n1905 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/libthrift-0.12.0.jar\n1907 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/log4j-1.2.17.jar\n1909 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/logging-interceptor-3.12.6.jar\n1911 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/lz4-java-1.7.1.jar\n1913 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/machinist_2.12-0.6.8.jar\n1914 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/macro-compat_2.12-1.1.1.jar\n1917 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/mesos-1.4.0-shaded-protobuf.jar\n1920 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/metrics-core-4.1.1.jar\n1922 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/metrics-graphite-4.1.1.jar\n1924 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/metrics-jmx-4.1.1.jar\n1926 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/metrics-json-4.1.1.jar\n1928 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/metrics-jvm-4.1.1.jar\n1931 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/minlog-1.3.0.jar\n1933 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/mysql-connector-java-5.1.47.jar\n1934 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/netty-all-4.1.47.Final.jar\n1936 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/nimbus-jose-jwt-4.41.1.jar\n1939 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/objenesis-2.5.1.jar\n1941 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/okhttp-2.7.5.jar\n1943 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/okhttp-3.12.6.jar\n1946 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/okio-1.15.0.jar\n1948 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/opencsv-2.3.jar\n1950 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/orc-core-1.5.10.jar\n1952 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/orc-mapreduce-1.5.10.jar\n1954 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/orc-shims-1.5.10.jar\n1955 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/oro-2.0.8.jar\n1957 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/osgi-resource-locator-1.0.3.jar\n1959 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/paranamer-2.8.jar\n1961 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/parquet-column-1.10.1.jar\n1963 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/parquet-common-1.10.1.jar\n1967 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/parquet-encoding-1.10.1.jar\n1969 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/parquet-format-2.4.0.jar\n1971 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/parquet-hadoop-1.10.1.jar\n1975 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/parquet-jackson-1.10.1.jar\n1977 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/postgresql-42.2.8.jar\n1979 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/protobuf-java-2.5.0.jar\n1982 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/py4j-0.10.9.jar\n1984 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/pyrolite-4.30.jar\n1986 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/re2j-1.1.jar\n1989 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/scala-collection-compat_2.12-2.1.1.jar\n1990 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/scala-compiler-2.12.10.jar\n1992 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/scala-library-2.12.10.jar\n1994 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/scala-parser-combinators_2.12-1.1.2.jar\n1996 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/scala-reflect-2.12.10.jar\n1998 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/scala-xml_2.12-1.2.0.jar\n2001 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/shapeless_2.12-2.3.3.jar\n2002 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/shims-0.7.45.jar\n2004 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/slf4j-api-1.7.30.jar\n2006 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/slf4j-log4j12-1.7.30.jar\n2008 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/snakeyaml-1.24.jar\n2010 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/snappy-java-1.1.7.5.jar\n2013 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/spark-avro_2.12-3.0.0.jar\n2015 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/spark-catalyst_2.12-3.0.0.jar\n2016 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/spark-core_2.12-3.0.0.jar\n2018 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/spark-graphx_2.12-3.0.0.jar\n2020 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/spark-hive-thriftserver_2.12-3.0.0.jar\n2022 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/spark-hive_2.12-3.0.0.jar\n2024 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/spark-kubernetes_2.12-3.0.0.jar\n2027 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/spark-kvstore_2.12-3.0.0.jar\n2029 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/spark-launcher_2.12-3.0.0.jar\n2031 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/spark-mesos_2.12-3.0.0.jar\n2033 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/spark-mllib-local_2.12-3.0.0.jar\n2035 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/spark-mllib_2.12-3.0.0.jar\n2037 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/spark-network-common_2.12-3.0.0.jar\n2040 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/spark-network-shuffle_2.12-3.0.0.jar\n2042 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/spark-repl_2.12-3.0.0.jar\n2043 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/spark-sketch_2.12-3.0.0.jar\n2046 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/spark-sql_2.12-3.0.0.jar\n2048 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/spark-streaming_2.12-3.0.0.jar\n2050 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/spark-tags_2.12-3.0.0-tests.jar\n2052 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/spark-tags_2.12-3.0.0.jar\n2054 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/spark-unsafe_2.12-3.0.0.jar\n2058 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/spark-yarn_2.12-3.0.0.jar\n2060 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/spire-macros_2.12-0.17.0-M1.jar\n2063 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/spire-platform_2.12-0.17.0-M1.jar\n2066 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/spire-util_2.12-0.17.0-M1.jar\n2069 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/spire_2.12-0.17.0-M1.jar\n2071 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/stax-api-1.0.1.jar\n2074 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/stax2-api-3.1.4.jar\n2076 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/stream-2.9.6.jar\n2078 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/super-csv-2.2.0.jar\n2081 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/threeten-extra-1.5.0.jar\n2083 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/token-provider-1.0.1.jar\n2085 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/transaction-api-1.1.jar\n2087 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/univocity-parsers-2.8.3.jar\n2090 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/velocity-1.5.jar\n2092 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/woodstox-core-5.0.3.jar\n2094 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/xbean-asm7-shaded-4.15.jar\n2096 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/xz-1.5.jar\n2098 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/zjsonpatch-0.3.0.jar\n2100 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/zookeeper-3.4.14.jar\n2102 [main] INFO  org.apache.spark.deploy.yarn.Client  - Source and destination file systems are the same. Not copying hdfs://master:9000/spark-jars/zstd-jni-1.4.4-3.jar\n2113 [main] INFO  org.apache.spark.deploy.yarn.Client  - Uploading resource file:/usr/program/livy/rsc-jars/asm-5.0.4.jar -\u003e hdfs://master:9000/user/root/.sparkStaging/application_1652142098641_0004/asm-5.0.4.jar\n2261 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation  - No unit for dfs.client.datanode-restart.timeout(30) assuming SECONDS\n2268 [main] INFO  org.apache.spark.deploy.yarn.Client  - Uploading resource file:/usr/program/livy/rsc-jars/livy-api-0.8.0-incubating-SNAPSHOT.jar -\u003e hdfs://master:9000/user/root/.sparkStaging/application_1652142098641_0004/livy-api-0.8.0-incubating-SNAPSHOT.jar\n2292 [main] INFO  org.apache.spark.deploy.yarn.Client  - Uploading resource file:/usr/program/livy/rsc-jars/livy-rsc-0.8.0-incubating-SNAPSHOT.jar -\u003e hdfs://master:9000/user/root/.sparkStaging/application_1652142098641_0004/livy-rsc-0.8.0-incubating-SNAPSHOT.jar\n2327 [main] INFO  org.apache.spark.deploy.yarn.Client  - Uploading resource file:/usr/program/livy/rsc-jars/livy-thriftserver-session-0.8.0-incubating-SNAPSHOT.jar -\u003e hdfs://master:9000/user/root/.sparkStaging/application_1652142098641_0004/livy-thriftserver-session-0.8.0-incubating-SNAPSHOT.jar\n2362 [main] WARN  org.apache.spark.deploy.yarn.Client  - Same name resource file:///usr/program/livy/rsc-jars/minlog-1.3.0.jar added multiple times to distributed cache\n2362 [main] WARN  org.apache.spark.deploy.yarn.Client  - Same name resource file:///usr/program/livy/rsc-jars/netty-all-4.1.47.Final.jar added multiple times to distributed cache\n2362 [main] WARN  org.apache.spark.deploy.yarn.Client  - Same name resource file:///usr/program/livy/rsc-jars/objenesis-2.5.1.jar added multiple times to distributed cache\n2363 [main] INFO  org.apache.spark.deploy.yarn.Client  - Uploading resource file:/usr/program/livy/rsc-jars/reflectasm-1.11.3.jar -\u003e hdfs://master:9000/user/root/.sparkStaging/application_1652142098641_0004/reflectasm-1.11.3.jar\n2394 [main] INFO  org.apache.spark.deploy.yarn.Client  - Uploading resource file:/usr/program/livy/repl_2.12-jars/commons-codec-1.9.jar -\u003e hdfs://master:9000/user/root/.sparkStaging/application_1652142098641_0004/commons-codec-1.9.jar\n2426 [main] INFO  org.apache.spark.deploy.yarn.Client  - Uploading resource file:/usr/program/livy/repl_2.12-jars/livy-core_2.12-0.8.0-incubating-SNAPSHOT.jar -\u003e hdfs://master:9000/user/root/.sparkStaging/application_1652142098641_0004/livy-core_2.12-0.8.0-incubating-SNAPSHOT.jar\n2460 [main] INFO  org.apache.spark.deploy.yarn.Client  - Uploading resource file:/usr/program/livy/repl_2.12-jars/livy-repl_2.12-0.8.0-incubating-SNAPSHOT.jar -\u003e hdfs://master:9000/user/root/.sparkStaging/application_1652142098641_0004/livy-repl_2.12-0.8.0-incubating-SNAPSHOT.jar\n2508 [main] INFO  org.apache.spark.deploy.yarn.Client  - Uploading resource file:/usr/program/spark/R/lib/sparkr.zip#sparkr -\u003e hdfs://master:9000/user/root/.sparkStaging/application_1652142098641_0004/sparkr.zip\n2562 [main] INFO  org.apache.spark.deploy.yarn.Client  - Uploading resource file:/usr/program/spark/python/lib/pyspark.zip -\u003e hdfs://master:9000/user/root/.sparkStaging/application_1652142098641_0004/pyspark.zip\n2591 [main] INFO  org.apache.spark.deploy.yarn.Client  - Uploading resource file:/usr/program/spark/python/lib/py4j-0.10.9-src.zip -\u003e hdfs://master:9000/user/root/.sparkStaging/application_1652142098641_0004/py4j-0.10.9-src.zip\n2614 [main] WARN  org.apache.spark.deploy.yarn.Client  - Same name resource file:///usr/program/spark/python/lib/pyspark.zip added multiple times to distributed cache\n2614 [main] WARN  org.apache.spark.deploy.yarn.Client  - Same name resource file:///usr/program/spark/python/lib/py4j-0.10.9-src.zip added multiple times to distributed cache\n2871 [main] INFO  org.apache.spark.deploy.yarn.Client  - Uploading resource file:/tmp/spark-13f8041e-33fa-4b96-ac58-21c3c5633827/__spark_conf__5810885990873377274.zip -\u003e hdfs://master:9000/user/root/.sparkStaging/application_1652142098641_0004/__spark_conf__.zip\n2945 [main] INFO  org.apache.spark.SecurityManager  - Changing view acls to: root\n2946 [main] INFO  org.apache.spark.SecurityManager  - Changing modify acls to: root\n2947 [main] INFO  org.apache.spark.SecurityManager  - Changing view acls groups to: \n2948 [main] INFO  org.apache.spark.SecurityManager  - Changing modify acls groups to: \n2948 [main] INFO  org.apache.spark.SecurityManager  - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\n3068 [main] INFO  org.apache.spark.deploy.yarn.Client  - Submitting application application_1652142098641_0004 to ResourceManager\n3137 [main] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl  - Submitted application application_1652142098641_0004\n3140 [main] INFO  org.apache.spark.deploy.yarn.Client  - Application report for application_1652142098641_0004 (state: ACCEPTED)\n3145 [main] INFO  org.apache.spark.deploy.yarn.Client  - \n\t client token: N/A\n\t diagnostics: N/A\n\t ApplicationMaster host: N/A\n\t ApplicationMaster RPC port: -1\n\t queue: root.root\n\t start time: 1652142641647\n\t final status: UNDEFINED\n\t tracking URL: http://master:8088/proxy/application_1652142098641_0004/\n\t user: root\n3150 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager  - Shutdown hook called\n3152 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager  - Deleting directory /tmp/spark-13f8041e-33fa-4b96-ac58-21c3c5633827\n3158 [shutdown-hook-0] INFO  org.apache.spark.util.ShutdownHookManager  - Deleting directory /tmp/spark-cb422152-c0a9-4261-8c0d-891796db1733\n\nstderr: \nSLF4J: Class path contains multiple SLF4J bindings.\nSLF4J: Found binding in [jar:file:/usr/program/spark/jars/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/usr/program/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\nSLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\n\nYARN Diagnostics: \nApplication application_1652142098641_0004 was killed by user root at 172.28.1.1\n\tat org.apache.zeppelin.livy.BaseLivyInterpreter.createSession(BaseLivyInterpreter.java:323)\n\t... 15 more\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1646274983841_2145158676",
      "id": "paragraph_1646190869578_526130353",
      "dateCreated": "2022-03-03 02:36:23.841",
      "dateStarted": "2022-05-10 00:30:32.300",
      "dateFinished": "2022-05-10 00:32:38.669",
      "status": "ERROR"
    },
    {
      "text": "%livy.spark\r\nsc.version",
      "user": "anonymous",
      "dateUpdated": "2022-05-10 00:10:31.852",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "res2: String \u003d 3.0.0"
          },
          {
            "type": "HTML",
            "data": "\u003chr/\u003eSpark Application Id: application_1652140577018_0004\u003cbr/\u003eSpark WebUI: \u003ca href\u003d\"http://master:8088/proxy/application_1652140577018_0004/\"\u003ehttp://master:8088/proxy/application_1652140577018_0004/\u003c/a\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1649603466732_667067385",
      "id": "paragraph_1649603466732_667067385",
      "dateCreated": "2022-04-10 15:11:06.732",
      "dateStarted": "2022-05-10 00:10:31.859",
      "dateFinished": "2022-05-10 00:10:32.893",
      "status": "FINISHED"
    },
    {
      "text": "%livy.pyspark\n\n#  PySpark over Livy\nimport sys\nprint(sys.version)\nspark.range(1000 * 1000 * 1000).count()",
      "user": "anonymous",
      "dateUpdated": "2022-05-10 00:10:35.666",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "python",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/python",
        "fontSize": 9.0,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "3.7.5 (default, May 10 2022, 07:44:22) \n[GCC 10.2.1 20210110]\n1000000000"
          },
          {
            "type": "HTML",
            "data": "\u003chr/\u003eSpark Application Id: application_1652140577018_0004\u003cbr/\u003eSpark WebUI: \u003ca href\u003d\"http://master:8088/proxy/application_1652140577018_0004/\"\u003ehttp://master:8088/proxy/application_1652140577018_0004/\u003c/a\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1646274983841_1917613680",
      "id": "paragraph_1646190869578_501472647",
      "dateCreated": "2022-03-03 02:36:23.841",
      "dateStarted": "2022-05-10 00:10:35.670",
      "dateFinished": "2022-05-10 00:10:37.732",
      "status": "FINISHED"
    },
    {
      "text": "%livy.sql\n-- not completed\nSELECT 1, CONCAT(\u0027This is\u0027, \u0027 a test\u0027)",
      "user": "anonymous",
      "dateUpdated": "2022-05-10 00:10:40.727",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "results": {
          "0": {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "1": "string",
                      "concat(This is,  a test)": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                }
              },
              "commonSetting": {}
            }
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TABLE",
            "data": "1\tconcat(This is,  a test)\n1\tThis is a test"
          },
          {
            "type": "HTML",
            "data": "\u003chr/\u003eSpark Application Id: application_1652140577018_0004\u003cbr/\u003eSpark WebUI: \u003ca href\u003d\"http://master:8088/proxy/application_1652140577018_0004/\"\u003ehttp://master:8088/proxy/application_1652140577018_0004/\u003c/a\u003e"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1646274983842_583690906",
      "id": "paragraph_1646190869578_1199924027",
      "dateCreated": "2022-03-03 02:36:23.842",
      "dateStarted": "2022-05-10 00:10:40.731",
      "dateFinished": "2022-05-10 00:10:43.819",
      "status": "FINISHED"
    },
    {
      "text": "%postgres\ncreate  schema if not exists pguser_public;\n\nset search_path\u003dpguser_public;\ndrop table if exists Course;\ncreate table Course(Cid varchar(10),Cname varchar(10),Tid varchar(10));\ninsert into Course values(\u002701\u0027 , \u0027语文\u0027 , \u002702\u0027);\ninsert into Course values(\u002702\u0027 , \u0027数学\u0027 , \u002701\u0027);\ninsert into Course values(\u002703\u0027 , \u0027英语\u0027 , \u002703\u0027);\n\nselect * from Course;",
      "user": "anonymous",
      "dateUpdated": "2022-05-10 00:10:49.982",
      "progress": 0,
      "config": {
        "editorSetting": {
          "language": "sql",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/sql",
        "fontSize": 9.0,
        "results": {
          "7": {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "setting": {
                "table": {
                  "tableGridState": {},
                  "tableColumnTypeState": {
                    "names": {
                      "cid": "string",
                      "cname": "string",
                      "tid": "string"
                    },
                    "updated": false
                  },
                  "tableOptionSpecHash": "[{\"name\":\"useFilter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable filter for columns\"},{\"name\":\"showPagination\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable pagination for better navigation\"},{\"name\":\"showAggregationFooter\",\"valueType\":\"boolean\",\"defaultValue\":false,\"widget\":\"checkbox\",\"description\":\"Enable a footer for displaying aggregated values\"}]",
                  "tableOptionValue": {
                    "useFilter": false,
                    "showPagination": false,
                    "showAggregationFooter": false
                  },
                  "updated": false,
                  "initialized": false
                }
              },
              "commonSetting": {}
            }
          }
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "Query executed successfully. Affected rows : 0\n\n"
          },
          {
            "type": "TEXT",
            "data": "Query executed successfully. Affected rows : 0\n\n"
          },
          {
            "type": "TEXT",
            "data": "Query executed successfully. Affected rows : 0\n\n"
          },
          {
            "type": "TEXT",
            "data": "Query executed successfully. Affected rows : 0\n\n"
          },
          {
            "type": "TEXT",
            "data": "Query executed successfully. Affected rows : 1\n\n"
          },
          {
            "type": "TEXT",
            "data": "Query executed successfully. Affected rows : 1\n\n"
          },
          {
            "type": "TEXT",
            "data": "Query executed successfully. Affected rows : 1\n"
          },
          {
            "type": "TABLE",
            "data": "cid\tcname\ttid\n01\t语文\t02\n02\t数学\t01\n03\t英语\t03\n"
          }
        ]
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1646274983842_1698947215",
      "id": "paragraph_1646191463203_1409418707",
      "dateCreated": "2022-03-03 02:36:23.842",
      "dateStarted": "2022-05-10 00:10:49.986",
      "dateFinished": "2022-05-10 00:10:53.108",
      "status": "FINISHED"
    },
    {
      "text": "%postgres\n",
      "user": "anonymous",
      "dateUpdated": "2022-04-20 12:23:23.820",
      "progress": 0,
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "runtimeInfos": {},
      "progressUpdateIntervalMs": 500,
      "jobName": "paragraph_1650457403820_1094750382",
      "id": "paragraph_1650457403820_1094750382",
      "dateCreated": "2022-04-20 12:23:23.820",
      "status": "READY"
    }
  ],
  "name": "test",
  "id": "2GVH229ZX",
  "defaultInterpreterGroup": "spark",
  "version": "0.9.0",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {},
  "config": {
    "isZeppelinNotebookCronEnable": false
  },
  "info": {}
}